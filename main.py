# -*- coding: utf-8 -*-
"""NLP Project - Kelompok 19.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1E5eGnJq92_DsOWt3EBFFK9jUpQMzx5hm
"""

# Commented out IPython magic to ensure Python compatibility.
# Import Library
import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline
import plotly.express as px

import re
import string
import nltk
from nltk.stem import WordNetLemmatizer
from nltk.corpus import stopwords
from collections import Counter
from wordcloud import WordCloud

from sklearn.pipeline import Pipeline
from sklearn import preprocessing
from sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

!unzip '/content/Dataset.zip' -d './dataset'

# Load Data
df = pd.read_csv('/content/dataset/movie.csv')
df.head()

"""# Explanatory Data Analysis and Visualization"""

# Decoder The Label from Dataset
df['label'] = df['label'].replace([0], 'negative')
df['label'] = df['label'].replace([1], 'positive')
df.head()

# Show Information of Dataset
df.info()

# Show Missing Value from Dataset
df.isnull().sum()

# Generating a Count Plot for Label
plt.figure(figsize = (10, 5))
sns.barplot(x = df['label'].value_counts().index, y = df['label'].value_counts())
plt.title('Review Count')
plt.xlabel('Review')
plt.ylabel('Count')

"""# Data Preprocessing"""

# Function to Convert Text to Lowercase and Remove Punctuation
def clean_text(text):
    text = str(text).lower()
    text = re.sub('\[.*?\]', '', text)
    text = re.sub('https?://\S+|www\.\S+', '', text)
    text = re.sub('<.*?>+', '', text)
    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)
    text = re.sub('\n', '', text)
    text = re.sub('\w*\d\w*', '', text)
    return text

# Show Data
df['clean'] = df['text'].apply(clean_text)
df.head()

nltk.download('stopwords')

# Function to Remove Stop Words
sws = stopwords.words('english')

def preprocessdata(text):
    text= ' '.join(word for word in text.split(' ') if word not in sws)
    return text

# Show Data
df['final'] = df['clean'].apply(preprocessdata)
df.head()

# Show Data
df['final2'] = df['final'].apply(lambda x:' '.join(text for text in x.split(' ') if len(text)>2))
df.head()

"""Word Cloud"""

# Word Cloud for Negative Sentiment
plt.figure(figsize = (15, 10))
wc = WordCloud(max_words = 500, background_color = 'black')
wc.generate(' '.join(word for word in df.loc[df['label'] == 'negative', 'final2']))
plt.imshow(wc)
plt.axis('off')
plt.show()

# Word Cloud for Positive Sentiment
plt.figure(figsize = (15, 10))
wc = WordCloud(max_words = 500, background_color = 'black')
wc.generate(' '.join(word for word in df.loc[df['label'] == 'positive','final2']))
plt.imshow(wc)
plt.axis('off')
plt.show()

"""Separate Variable"""

# Separate The Variables in The Dataset Into Independent Variables and Dependent Variable
X = df['final2']
y = df['label']

"""Encoder"""

label = preprocessing.LabelEncoder()
label.fit(y)
y = label.transform(y)

"""Split The Dataset"""

# Split The Dataset Into Training Set (75%) and Testing Set (25%)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 105)

"""# Modelling"""

pipe = Pipeline([('bow', CountVectorizer()),('tfidf', TfidfTransformer()),('model', LogisticRegression())])

# Train Model
pipe.fit(X_train, y_train)

# Predict Model
y_pred = pipe.predict(X_test)

# Evaluate Model
print('EVALUATION MODEL')
print(confusion_matrix(y_test, y_pred, labels = [0, 1]))
print(classification_report(y_test, y_pred, labels = [0, 1]))
print('\nAccuracy Score: ', accuracy_score(y_test, y_pred))

y_pred = label.inverse_transform(y_pred)
y_test = label.inverse_transform(y_test)

result = pd.DataFrame({'Test' : X_test[20 : 30], 'Prediction' : y_pred[20 : 30], 'Actual' : y_test[20 : 30]})
result.head()

"""# Prediction Sentiment Using Input from User"""

demo = input("Input Comment: ")
demo = [demo]

pipe = Pipeline([('bow', CountVectorizer()), ('tfidf', TfidfTransformer()),('model', LogisticRegression())])
pipe.fit(X_train, y_train)
y_pred = pipe.predict(demo)
y_pred = label.inverse_transform(y_pred)

print("Result:", y_pred[0])